{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying hand gestures with LSTM and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 360\n"
     ]
    }
   ],
   "source": [
    "# Gather data set into paths and class labels\n",
    "import glob, os\n",
    "import re\n",
    "\n",
    "paths = []\n",
    "labels = []\n",
    "for path, subdirs, files in os.walk('DigitData'):\n",
    "    for name in files:\n",
    "        paths.append(os.path.join(path, name))\n",
    "        labels.append(re.split(r'(\\d+)', name)[0])\n",
    "print(len(paths), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T_T', 'I_M', 'HC_', 'M_M', 'IMR', 'T_M', 'T_R', 'M_R', 'I_I', 'R_R', 'T_I', 'R_L', 'MRL', 'L_L', 'T_L'} 15\n"
     ]
    }
   ],
   "source": [
    "# Verify we have 15 unique classes\n",
    "myset = set(labels)\n",
    "num_classes = len(myset)\n",
    "print(myset, num_classes)\n",
    "import pandas as pd\n",
    "#Get shape if input data\n",
    "df = pd.read_csv(paths[0], header=None, nrows=20000)\n",
    "timestep = df.shape[0]\n",
    "num_channels = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with x data\n",
    "import numpy as np\n",
    "#Initialize x data\n",
    "x_data = np.empty((len(paths), timestep, num_channels), dtype=np.float32)\n",
    "#Load dat to tensor\n",
    "for i, path in enumerate(paths):\n",
    "    data = pd.read_csv(path, header=None, nrows=20000)\n",
    "    x_data[i,:,:] = data.values\n",
    "import scipy.signal as sg\n",
    "decimated = sg.decimate(x_data, axis = 1, q =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  9,  0,  1, 10, 14,  6,  3, 10, 11,  8,  3, 12,  5,  8,  1,  6,\n",
       "       13,  5, 11, 12,  0, 12,  0,  3,  2,  5,  9,  9,  8,  1,  2, 14, 14,\n",
       "       11,  4,  7, 13,  4,  2,  6, 10, 13,  7,  7,  4,  9,  0,  1, 10, 14,\n",
       "        6,  3, 10, 11,  8,  3, 12,  5,  8,  1,  6, 13,  5, 11, 12,  0, 12,\n",
       "        0,  3,  2,  5,  9,  9,  8,  1,  2, 14, 14, 11,  4,  7, 13,  4,  2,\n",
       "        6, 10, 13,  7,  7,  4,  9,  0,  1, 10, 14,  6,  3, 10, 11,  8,  3,\n",
       "       12,  5,  8,  1,  6, 13,  5, 11, 12,  0, 12,  0,  3,  2,  5,  9,  9,\n",
       "        8,  1,  2, 14, 14, 11,  4,  7, 13,  4,  2,  6, 10, 13,  7,  7,  4,\n",
       "        9,  0,  1, 10, 14,  6,  3, 10, 11,  8,  3, 12,  5,  8,  1,  6, 13,\n",
       "        5, 11, 12,  0, 12,  0,  3,  2,  5,  9,  9,  8,  1,  2, 14, 14, 11,\n",
       "        4,  7, 13,  4,  2,  6, 10, 13,  7,  7,  4,  9,  0,  1, 10, 14,  6,\n",
       "        3, 10, 11,  8,  3, 12,  5,  8,  1,  6, 13,  5, 11, 12,  0, 12,  0,\n",
       "        3,  2,  5,  9,  9,  8,  1,  2, 14, 14, 11,  4,  7, 13,  4,  2,  6,\n",
       "       10, 13,  7,  7,  4,  9,  0,  1, 10, 14,  6,  3, 10, 11,  8,  3, 12,\n",
       "        5,  8,  1,  6, 13,  5, 11, 12,  0, 12,  0,  3,  2,  5,  9,  9,  8,\n",
       "        1,  2, 14, 14, 11,  4,  7, 13,  4,  2,  6, 10, 13,  7,  7,  4,  9,\n",
       "        0,  1, 10, 14,  6,  3, 10, 11,  8,  3, 12,  5,  8,  1,  6, 13,  5,\n",
       "       11, 12,  0, 12,  0,  3,  2,  5,  9,  9,  8,  1,  2, 14, 14, 11,  4,\n",
       "        7, 13,  4,  2,  6, 10, 13,  7,  7,  4,  9,  0,  1, 10, 14,  6,  3,\n",
       "       10, 11,  8,  3, 12,  5,  8,  1,  6, 13,  5, 11, 12,  0, 12,  0,  3,\n",
       "        2,  5,  9,  9,  8,  1,  2, 14, 14, 11,  4,  7, 13,  4,  2,  6, 10,\n",
       "       13,  7,  7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dealing with y data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#Change class label to one-hot vectors \n",
    "le = LabelEncoder()\n",
    "one_hot = OneHotEncoder(sparse = False)\n",
    "\n",
    "#Convert to ints\n",
    "le.fit(list(myset))\n",
    "int_labels = le.transform(labels)\n",
    "int_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data to train test val split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(decimated,int_labels, test_size = 0.2, random_state=40, \n",
    "                                                   stratify = int_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "channel_means = np.mean(X_train, axis = (0,1)).reshape(1,8)\n",
    "channel_std = np.std(X_train, axis = (0,1)).reshape(1,8)\n",
    "X_train -= channel_means\n",
    "X_train /= channel_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train into train-val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state=40, \n",
    "                                                 stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Keras model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256,\n",
    "              input_shape = (1000, num_channels), return_sequences = True))\n",
    "model.add(LSTM(256, return_sequences = True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer= 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/50\n",
      "230/230 [==============================] - 30s 132ms/step - loss: 2.6678 - acc: 0.1130 - val_loss: 2.6908 - val_acc: 0.1207\n",
      "Epoch 2/50\n",
      "230/230 [==============================] - 28s 121ms/step - loss: 2.5395 - acc: 0.0957 - val_loss: 2.5798 - val_acc: 0.1034\n",
      "Epoch 3/50\n",
      "230/230 [==============================] - 29s 126ms/step - loss: 2.4489 - acc: 0.1435 - val_loss: 2.5075 - val_acc: 0.1034\n",
      "Epoch 4/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 2.3965 - acc: 0.1652 - val_loss: 2.4034 - val_acc: 0.1552\n",
      "Epoch 5/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 2.3639 - acc: 0.1478 - val_loss: 2.4268 - val_acc: 0.1379\n",
      "Epoch 6/50\n",
      "230/230 [==============================] - 29s 128ms/step - loss: 2.2999 - acc: 0.1696 - val_loss: 2.3633 - val_acc: 0.1552\n",
      "Epoch 7/50\n",
      "230/230 [==============================] - 30s 129ms/step - loss: 2.2023 - acc: 0.1913 - val_loss: 2.3388 - val_acc: 0.2069\n",
      "Epoch 8/50\n",
      "230/230 [==============================] - 29s 125ms/step - loss: 2.1264 - acc: 0.2391 - val_loss: 2.2878 - val_acc: 0.2241\n",
      "Epoch 9/50\n",
      "230/230 [==============================] - 30s 128ms/step - loss: 2.1096 - acc: 0.2565 - val_loss: 2.3200 - val_acc: 0.2069\n",
      "Epoch 10/50\n",
      "230/230 [==============================] - 29s 128ms/step - loss: 2.1132 - acc: 0.2783 - val_loss: 2.2391 - val_acc: 0.1897\n",
      "Epoch 11/50\n",
      "230/230 [==============================] - 30s 132ms/step - loss: 2.0435 - acc: 0.2391 - val_loss: 2.1534 - val_acc: 0.2241\n",
      "Epoch 12/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 1.9375 - acc: 0.3348 - val_loss: 2.2268 - val_acc: 0.2414\n",
      "Epoch 13/50\n",
      "230/230 [==============================] - 30s 128ms/step - loss: 2.0350 - acc: 0.2478 - val_loss: 2.3082 - val_acc: 0.2069\n",
      "Epoch 14/50\n",
      "230/230 [==============================] - 30s 129ms/step - loss: 2.0648 - acc: 0.2696 - val_loss: 2.1462 - val_acc: 0.2241\n",
      "Epoch 15/50\n",
      "230/230 [==============================] - 30s 129ms/step - loss: 1.9991 - acc: 0.2391 - val_loss: 2.3440 - val_acc: 0.1897\n",
      "Epoch 16/50\n",
      "230/230 [==============================] - 30s 129ms/step - loss: 2.0200 - acc: 0.2565 - val_loss: 2.2047 - val_acc: 0.1724\n",
      "Epoch 17/50\n",
      "230/230 [==============================] - 30s 132ms/step - loss: 1.9431 - acc: 0.3087 - val_loss: 2.1478 - val_acc: 0.1897\n",
      "Epoch 18/50\n",
      "230/230 [==============================] - 30s 130ms/step - loss: 2.0194 - acc: 0.2652 - val_loss: 2.1963 - val_acc: 0.1897\n",
      "Epoch 19/50\n",
      "230/230 [==============================] - 30s 129ms/step - loss: 1.8961 - acc: 0.3043 - val_loss: 2.4466 - val_acc: 0.1897\n",
      "Epoch 20/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 1.9920 - acc: 0.3087 - val_loss: 2.2843 - val_acc: 0.2586\n",
      "Epoch 21/50\n",
      "230/230 [==============================] - 29s 124ms/step - loss: 2.0071 - acc: 0.2739 - val_loss: 2.2259 - val_acc: 0.2241\n",
      "Epoch 22/50\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 1.9623 - acc: 0.2783 - val_loss: 2.3259 - val_acc: 0.1724\n",
      "Epoch 23/50\n",
      "230/230 [==============================] - 29s 125ms/step - loss: 1.8314 - acc: 0.3000 - val_loss: 2.1938 - val_acc: 0.1379\n",
      "Epoch 24/50\n",
      "230/230 [==============================] - 28s 124ms/step - loss: 1.7557 - acc: 0.3391 - val_loss: 2.2426 - val_acc: 0.1552\n",
      "Epoch 25/50\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 1.6610 - acc: 0.3783 - val_loss: 2.2222 - val_acc: 0.2241\n",
      "Epoch 26/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 1.6715 - acc: 0.3696 - val_loss: 2.2200 - val_acc: 0.2069\n",
      "Epoch 27/50\n",
      "230/230 [==============================] - 29s 125ms/step - loss: 1.6483 - acc: 0.4043 - val_loss: 2.1757 - val_acc: 0.2414\n",
      "Epoch 28/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 1.5667 - acc: 0.4348 - val_loss: 2.2021 - val_acc: 0.2414\n",
      "Epoch 29/50\n",
      "230/230 [==============================] - 29s 125ms/step - loss: 1.6035 - acc: 0.3913 - val_loss: 2.1772 - val_acc: 0.1724\n",
      "Epoch 30/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 1.5901 - acc: 0.3826 - val_loss: 2.3037 - val_acc: 0.1552\n",
      "Epoch 31/50\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 1.6445 - acc: 0.3870 - val_loss: 2.3034 - val_acc: 0.2414\n",
      "Epoch 32/50\n",
      "230/230 [==============================] - 28s 124ms/step - loss: 1.5671 - acc: 0.4087 - val_loss: 2.1826 - val_acc: 0.2069\n",
      "Epoch 33/50\n",
      "230/230 [==============================] - 29s 126ms/step - loss: 1.5450 - acc: 0.4435 - val_loss: 2.2427 - val_acc: 0.2069\n",
      "Epoch 34/50\n",
      "230/230 [==============================] - 29s 126ms/step - loss: 1.4995 - acc: 0.4652 - val_loss: 2.1341 - val_acc: 0.1552\n",
      "Epoch 35/50\n",
      "230/230 [==============================] - 29s 125ms/step - loss: 1.5502 - acc: 0.4304 - val_loss: 2.1964 - val_acc: 0.1897\n",
      "Epoch 36/50\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 1.4284 - acc: 0.4565 - val_loss: 2.3267 - val_acc: 0.1552\n",
      "Epoch 37/50\n",
      "230/230 [==============================] - 29s 124ms/step - loss: 1.4460 - acc: 0.4565 - val_loss: 2.1252 - val_acc: 0.2586\n",
      "Epoch 38/50\n",
      "230/230 [==============================] - 29s 125ms/step - loss: 1.4218 - acc: 0.4609 - val_loss: 2.2015 - val_acc: 0.2241\n",
      "Epoch 39/50\n",
      "230/230 [==============================] - 30s 130ms/step - loss: 1.2996 - acc: 0.5261 - val_loss: 2.3930 - val_acc: 0.2241\n",
      "Epoch 40/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 1.3341 - acc: 0.5435 - val_loss: 2.3794 - val_acc: 0.2759\n",
      "Epoch 41/50\n",
      "230/230 [==============================] - 29s 127ms/step - loss: 2.2809 - acc: 0.3957 - val_loss: 2.8394 - val_acc: 0.1379\n",
      "Epoch 42/50\n",
      "230/230 [==============================] - 29s 126ms/step - loss: 2.5909 - acc: 0.1304 - val_loss: 2.7715 - val_acc: 0.0862\n",
      "Epoch 43/50\n",
      "230/230 [==============================] - 29s 125ms/step - loss: 2.6682 - acc: 0.1217 - val_loss: 2.7188 - val_acc: 0.0862\n",
      "Epoch 44/50\n",
      "230/230 [==============================] - 29s 128ms/step - loss: 2.5266 - acc: 0.1478 - val_loss: 2.7011 - val_acc: 0.0690\n",
      "Epoch 45/50\n",
      "230/230 [==============================] - 30s 130ms/step - loss: 2.4954 - acc: 0.1739 - val_loss: 2.6673 - val_acc: 0.1034\n",
      "Epoch 46/50\n",
      "230/230 [==============================] - 30s 131ms/step - loss: 2.4842 - acc: 0.1130 - val_loss: 2.6703 - val_acc: 0.1207\n",
      "Epoch 47/50\n",
      "230/230 [==============================] - 30s 130ms/step - loss: 2.8404 - acc: 0.1087 - val_loss: 2.7895 - val_acc: 0.0862\n",
      "Epoch 48/50\n",
      "230/230 [==============================] - 30s 130ms/step - loss: 2.7485 - acc: 0.0913 - val_loss: 2.7273 - val_acc: 0.0862\n",
      "Epoch 49/50\n",
      "230/230 [==============================] - 29s 128ms/step - loss: 2.6913 - acc: 0.0957 - val_loss: 2.6774 - val_acc: 0.1034\n",
      "Epoch 50/50\n",
      "230/230 [==============================] - 30s 129ms/step - loss: 2.6874 - acc: 0.0696 - val_loss: 2.6643 - val_acc: 0.0862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56f93f2470>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 15)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a70009143d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
